<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pankhuri Vanjani</title>
  
  <meta name="author" content="Moritz Reuss">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pankhuri Vanjani</name>
              </p>
              <p>I am a PhD student in the <a href="https://irl.anthropomatik.kit.edu/">Intuitive Robots Lab</a> (IRL) at the Karlsruhe Institute of Technology (KIT), Germany supervised by <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a>
                My research focuses on Learning robust and explainable policies from multimodal modalities for robot tasks. 
                Previously, I obtained my Master Degree in Embedded Systems(Computer Science) at the Saarland University where I wrote my thesis at Max Planck Institute supervised by <a href="https://people.mpi-inf.mpg.de/~golyanik/">Vladislav Golyanik</a>.
                
              </p>

              <p style="text-align:center">
                <a href="mailto:pankhurivanjani@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/pankhuriCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.de/citations?user=P4LhJLgAAAAJ&hl=de">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/pankhurivanjani/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/pankhuri-vanjani-767283101/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/pankhuri-red.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pankhuri-red.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research focuses on developing robust robot policies that can operate reliably in complex, real-world environments by leveraging multiple sensor modalities, such as vision, force, tactile, and language. 
		I aim to build intelligent embodied agents that learn fine grained manipulation skills to perform a given task. 
		This includes designing models adapting to sensor failures, noise, or incomplete observations, thereby improving resilience and reliability. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

</tbody>


	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="background-color: #ffffd0;">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <div style="display: flex;">
                  <div style="flex: 0 0 25%; max-width: 25%;">
                    <img src='images/disp.png' style="width: 100%; max-width: 100%;">
                  </div>
                  <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                    <a href="https://openreview.net/pdf?id=nDmwloEl3N">
                      <papertitle>DisDP: Robust Imitation Learning via Disentangled Diffusion Policies</papertitle>
                    </a>
                    <br>
                    <strong>Pankhuri Vanjani*</strong>,
                    <a >Paul Mattes</a>,
                    <a >Xiaogang Jia</a>,
		    <a >Vedant Dave</a>,
                    <a href="http://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a> <br>
                    <br>
                    Reinforcement Learning Conference(RLC) 2025, Ext. Abstract at German Robotics Conference (GRC) 2025
                    <br>
                      
                  <a href="https://openreview.net/forum?id=0GSL9VRBib&noteId=0P93HqQSgo">OpenReviewnet</a>
                  <p></p>
                    <p>
                      We propose Mixture-of-Denoising Experts (MoDE) as a novel generalist policy for guided behavior generation, that outperforms dense transformer-based Diffusion Policies in performance, number of parameters and efficiency. 
                      Our proposed method introduces a novel routing strategy, that conditions the expert selection on the current noise level of the diffusion process. We test MoDE on four established imitation learning benchmarks, including CALVIN and LIBERO. 
                      In our experiments, MoDE consistently outperforms dense transformer architectures and state-of-the-art baselines on CALVIN and LIBERO benchmark. 
                      We pretrain MoDE on a subset of OXE for just 3 days on 6 GPUS to surpass OpenVLA and Octo in terms of performance on SIMPLER.
                      In addition, MoDE achieves higher average performance with 90% less FLOPS, 20% faster inference and 40% less parameters compared to the dense transformer diffusion policy.
                    </p>
                  </div>
                </div>
              </td>
            </tr>
            <tr>
		    

          <tr style="background-color: #ffffd0;">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <div style="display: flex;">
                    <div style="flex: 0 0 25%; max-width: 25%;">
                        <img src='images/communication.jpg' style="width: 100%; max-width: 100%;">
                    </div>
                    <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                        <a href="https://www.sciencedirect.com/science/article/pii/S1084804520302137">
                  <papertitle>Communication and networking technologies for UAVs: A survey </papertitle>
                </a>
                <br>
                <br>
                <em> Journal of Network and Computer Applications</em>, 2020
                <br>
                <a href="https://www.sciencedirect.com/science/article/pii/S1084804520302137">sciencedirect</a>
                <p></p>
                <p>
                 This paper aims at providing insights into the latest UAV (Unmanned Aerial Vehicle) 
		communication technologies through investigation of suitable task modules, antennas, resource handling platforms, 
		and network architectures. 
		Additionally, we explore techniques such as machine learning and path planning to enhance existing drone communication methods</p>
              </td>
            </tr>



	  
          <tr style="background-color: #ffffd0;">
              <td style="padding:20px;width:100%;vertical-align:middle">
                <div style="display: flex;">
                    <div style="flex: 0 0 25%; max-width: 25%;">
                        <img src='images/leafy.png' style="width: 100%; max-width: 100%;">
                    </div>
                    <div style="flex: 0 0 75%; max-width: 75%; padding-left: 20px;">
                        <a href="https://www.researchgate.net/publication/335051252_Image_processing-based_intelligent_robotic_system_for_assistance_of_agricultural_crops">
                  <papertitle>Image processing-based intelligent robotic system for assistance of agricultural crops </papertitle>
                </a>
                <br>
                <br>
                <em> International Journal of Social and Humanistic Computing</em>, 2019
                <br>
                <a href="https://www.researchgate.net/publication/335051252_Image_processing-based_intelligent_robotic_system_for_assistance_of_agricultural_crops">researchgate</a>
                <p></p>
                <p>
                This paper presents improved image processing algorithms for detecting leaf infections and uses k-means clustering for agricultural field classification in a heterogeneous robotic system. 
		The approach leverages a dataset of 3,150 crop disease images across three crop types, aiming to enable early disease detection and support mixed cropping via smart farming technologies.</p>
              </td>
            </tr>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
      <td style="padding:0px; vertical-align: middle;">
          <br>
          <p style="text-align:right;font-size:small;">
              The website is based on the code from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>!
          </p>
      </td>
  </tr>
</tbody></table>
</body>

</html>
